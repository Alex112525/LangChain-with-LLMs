{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNDP9GGPL82vpOp1zdD3VC4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alex112525/LangChain-with-LLMs/blob/main/Embeddings_and_VectorStores_Langchain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2VrX4sdMP4KF"
      },
      "outputs": [],
      "source": [
        "!pip install langchain pypdf sentence_transformers chromadb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "dVDy-gwuTYBm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embeddings"
      ],
      "metadata": {
        "id": "7vYE1XSuSFGt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "An embedding is a relatively low-dimensional space into which you can translate high-dimensional vectors.\n",
        "\n",
        "Embeddings make it easier to do machine learning on large inputs like sparse vectors representing words. Ideally, an embedding captures some of the semantics of the input by placing semantically similar inputs close together in the embedding space"
      ],
      "metadata": {
        "id": "055thiksSHL1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### HuggingFace Embeddings"
      ],
      "metadata": {
        "id": "iR2XRD9iWNPv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "embedding = HuggingFaceEmbeddings()"
      ],
      "metadata": {
        "id": "uWjfnK5fRYlt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [\"I like Hamburguers\", \"I like Pizza\", \"I like Programming\", \"The weather is cool outside\"]\n",
        "embeddings = [embedding.embed_query(sen) for sen in sentences]"
      ],
      "metadata": {
        "id": "ftXYiJemRugS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(embeddings[0])\n",
        "len(embeddings[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mh-pygJlTIba",
        "outputId": "507a31fe-74dd-48f4-ad0c-b7fc5e9da988"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.02939228154718876, 0.08986327797174454, -0.0007837651646696031, -0.04436204954981804, -0.010849258862435818, 0.01615643873810768, -0.02946549840271473, -0.02205762080848217, 0.03789498284459114, 0.00710664689540863, -0.036479778587818146, -0.0306805782020092, -0.008992488496005535, -0.016738422214984894, -0.01777016371488571, -0.027559597045183182, 0.006301789544522762, -9.311235044151545e-05, -0.05282406881451607, -0.027767103165388107, -0.025167597457766533, -0.004394760355353355, -0.0152291813865304, 0.019534755498170853, 0.026362599804997444, -0.0005381685914471745, 0.0051782988011837006, -0.02530023083090782, -0.016055455431342125, -0.0001226386521011591, -0.002834279090166092, -0.03776457533240318, -0.03368791192770004, 0.016238775104284286, 1.3363209063754766e-06, 0.02781008929014206, -0.05031516030430794, 0.015401276759803295, -0.009767613373696804, 0.030515333637595177, 0.004960845224559307, -0.04259418323636055, -0.041071947664022446, -0.0077319275587797165, 0.011898662894964218, 0.01477715466171503, 0.038391388952732086, 0.04299422726035118, -0.039082422852516174, -0.009928805753588676, 0.001967765623703599, -0.09827449917793274, -0.0698389783501625, -0.012326590716838837, -0.00014433509204536676, 0.04222468286752701, 0.021146053448319435, 0.09254070371389389, 0.0029958393424749374, -0.002147338818758726, -0.02555922232568264, -0.0379193015396595, -0.026219962164759636, -0.011217750608921051, -0.04236701503396034, -0.019519522786140442, 0.007149829529225826, 0.029761429876089096, 0.05237549543380737, -0.025358615443110466, -0.012450387701392174, -0.06232735514640808, -0.037601422518491745, 0.0023747566156089306, 0.03018449805676937, -0.023259621113538742, -0.0017130491323769093, -0.026699038222432137, -0.01904994063079357, 0.006817608140408993, -0.02443019486963749, 0.0006029549986124039, -0.006769517902284861, 0.03682910278439522, -0.010999354533851147, 0.08568790555000305, 0.01828598417341709, 0.002610564697533846, 0.031834788620471954, 0.030187655240297318, -0.11030656844377518, -0.04273141920566559, 0.02011616714298725, 0.05313458666205406, -0.06472180038690567, -0.02972320467233658, -0.009941642172634602, -0.027497410774230957, 0.03356686234474182, 0.011544609442353249, -0.03312689810991287, 0.03650946170091629, -0.04116547480225563, -0.0020586519967764616, -0.032167430967092514, 0.02721519023180008, 0.04042806103825569, -0.00784502923488617, 0.018389688804745674, -0.07944796979427338, 0.023905664682388306, 0.032163284718990326, 0.03567080944776535, 0.029219359159469604, -0.005473249591886997, -0.03698792681097984, 0.013483836315572262, 0.03628375008702278, 0.01360193733125925, 0.033815644681453705, -0.026177871972322464, 0.010445556603372097, 0.011161993257701397, 0.03954554721713066, -0.02691836468875408, 0.03511505946516991, -0.04153107851743698, -0.00417656684294343, -0.03177495300769806, 0.009856023825705051, -0.04730480536818504, 0.021102089434862137, -0.027693932875990868, -0.01323847845196724, 0.05472385883331299, -0.018427960574626923, -0.054299246519804, -0.018803497776389122, 0.04448925331234932, -0.0067753056064248085, 0.010086641646921635, 0.007128603756427765, -0.006527803838253021, 0.005188994575291872, -0.020008418709039688, 0.016503218561410904, -0.006078174337744713, -0.06756609678268433, 0.02766377106308937, -0.0006033471436239779, -0.01979084312915802, -0.027854980900883675, -0.03402457386255264, -0.006886526010930538, -0.02976994775235653, -0.006384579930454493, -0.12081566452980042, -0.05615662410855293, -0.03237040340900421, 0.03696584329009056, 0.0165473110973835, -0.010299471206963062, 0.01124582253396511, -0.02542298473417759, -0.04550429433584213, -0.026500366628170013, -0.016139978542923927, 0.0008640651940368116, 0.008768406696617603, -0.018852222710847855, 0.07158517092466354, 0.012871799059212208, -0.01660098508000374, -0.07547194510698318, 0.09339792281389236, 0.03869006037712097, 0.025592174381017685, -0.007669665850698948, 0.012963362038135529, -0.048430342227220535, 0.021119263023138046, -0.01931419037282467, 0.025180207565426826, -0.04826711118221283, 0.0036615494173020124, 0.05793079361319542, -0.017814747989177704, 0.06922613084316254, 0.01914389431476593, -0.01588776521384716, 0.05471517890691757, 0.004137320909649134, 0.02392960712313652, -0.014340604655444622, -0.004358280915766954, 0.015344778075814247, -0.023734699934720993, -0.08103957772254944, 0.031182875856757164, 0.0013593914918601513, -0.007647562772035599, 0.04754585772752762, -0.007807067595422268, 0.036364227533340454, 0.04112335667014122, 0.0049040173180401325, -0.08438587933778763, -0.013934717513620853, -0.10749673843383789, -0.007781490217894316, 0.0587216317653656, 0.007126656826585531, 0.014847410842776299, -0.026145847514271736, 0.013728114776313305, 0.03220932185649872, 0.013209684751927853, 0.001643245224840939, 0.01148403249680996, 0.046059850603342056, -0.020124098286032677, 0.02361113391816616, 0.04728075489401817, 0.014607694931328297, 0.041228022426366806, 0.061886079609394073, 0.027075976133346558, -0.03698493540287018, 0.0004887597751803696, -0.004760274197906256, 0.010801311582326889, 0.03743504732847214, -0.019466642290353775, -0.017030617222189903, -0.0234838780015707, 0.057987894862890244, 0.08565432578325272, -0.042747482657432556, -0.03193925693631172, 0.043841294944286346, -0.008388004265725613, -0.06837045401334763, 0.03284242004156113, 0.014820770360529423, 0.006052407436072826, -0.02865307405591011, 0.06760451942682266, -0.028463250026106834, -0.03740489482879639, -0.02461664006114006, -0.020361723378300667, -0.021590720862150192, 0.015459633432328701, -0.0002270140394102782, -0.034737493842840195, -0.10847458243370056, 0.02246636338531971, -0.01706022210419178, -0.0087349321693182, -0.029233025386929512, 0.0349091999232769, -0.03263179585337639, 0.020874539390206337, 0.03025524877011776, 0.0475776232779026, -0.010282768867909908, 0.049013130366802216, -0.0483846589922905, -0.00792825035750866, 0.009140430018305779, 0.01899394579231739, -0.032743871212005615, 0.04398248717188835, 0.05330601707100868, -0.03127021715044975, 0.0025826659984886646, -0.03434913232922554, -0.02045837976038456, 0.010417270474135876, -0.019588932394981384, -0.0557478703558445, 0.0277464110404253, 0.012274294160306454, 0.04403652250766754, 0.0035973701160401106, 0.06140865385532379, -0.024364857003092766, -0.02062973938882351, -0.0048110606148839, -0.03688007593154907, -0.06434959173202515, 0.017694422975182533, 0.027784783393144608, -0.0022706089075654745, 0.0008884627604857087, 0.02818424627184868, 0.08260848373174667, 0.04965449124574661, -0.009540333412587643, -0.0431133434176445, -0.07865646481513977, 0.03810977563261986, -0.019558001309633255, 0.012351625598967075, -0.022498754784464836, 0.014746023342013359, -0.0042696367017924786, 0.032657016068696976, 0.021312285214662552, 0.03047339990735054, -0.007846382446587086, -0.023252926766872406, -0.02598630264401436, -0.04812520742416382, 0.047450046986341476, 0.032382071018218994, 0.010563726536929607, -0.033230431377887726, 0.02858820930123329, 0.005600941367447376, 0.028353316709399223, 0.01785777322947979, -0.01534847542643547, -0.0372682586312294, -0.010406449437141418, -0.0024314257316291332, -0.04061188921332359, -0.024375762790441513, 0.013646779581904411, 0.03854767233133316, 0.05144170671701431, -0.012802542187273502, 0.025107230991125107, 0.02805669791996479, -0.012436687014997005, -0.031084993854165077, -0.007527947425842285, 0.027188239619135857, 0.031698815524578094, -0.05860112980008125, 0.049933332949876785, -0.05691039189696312, -0.024525625631213188, 0.0008070779731497169, -0.07029997557401657, 0.05358799174427986, 0.04036437347531319, -0.03120848722755909, -0.11024247854948044, -0.013218886218965054, 0.05270175635814667, -0.05576110631227493, -0.02436162531375885, -0.02663828805088997, -0.010315640829503536, 0.0028118821792304516, -0.009091571904718876, 0.08259131014347076, -0.025019977241754532, 0.0007600858225487173, -0.03415365889668465, 0.024106619879603386, 0.021575992926955223, 0.01806332916021347, 0.008850842714309692, 0.009642825461924076, 0.025285795331001282, -0.01425879541784525, -0.002201283350586891, -0.0797593891620636, -0.008713606745004654, 0.019182991236448288, -0.03350232169032097, 0.0206295195966959, 0.006679833400994539, 0.010036862455308437, 0.019367752596735954, 0.03086179867386818, 0.09778794646263123, 0.01408432051539421, 0.056384146213531494, -0.03547682613134384, -0.03408600762486458, 0.043297987431287766, -0.022436413913965225, -0.05921506881713867, 0.012629133649170399, -0.0420917272567749, -0.08373097330331802, -0.052619077265262604, 0.0699545368552208, -0.05001252517104149, -0.013668106868863106, -0.046580828726291656, 0.010095619596540928, 0.035712145268917084, 0.009840469807386398, 0.012991000898182392, 0.020444059744477272, 0.035288821905851364, 0.040268272161483765, 0.02529071643948555, -0.020357517525553703, 0.012187179177999496, -0.021633461117744446, -0.022562427446246147, -0.004994909279048443, -0.01844133995473385, 0.06632458418607712, -0.06960710138082504, -0.018653804436326027, 0.04812905192375183, 0.0042366087436676025, -0.014974250458180904, -0.04668845236301422, -0.06556336581707001, -0.018173016607761383, -0.015713712200522423, 0.004595991689711809, 0.011874862015247345, -0.027556661516427994, -0.021969282999634743, 0.024440815672278404, -0.02385665662586689, 0.03617380931973457, 0.019085824489593506, 0.053957510739564896, 0.036308642476797104, 0.02619805745780468, 0.038999609649181366, 0.019636524841189384, -0.001130036311224103, -0.030828021466732025, -0.010899984277784824, -0.04280243068933487, -0.03317432850599289, 0.06275302171707153, 0.0018443891312927008, -0.0420185886323452, 0.026729753240942955, 0.016779927536845207, -0.0023234731052070856, 0.02763553522527218, -0.004418496508151293, 0.0423993319272995, -0.03413502871990204, -0.028620604425668716, -0.07056502252817154, -0.006092548370361328, 0.006461807526648045, -0.005994550418108702, -0.0627257451415062, -0.013756812550127506, 0.13903583586215973, 0.0012825671583414078, -0.045560143887996674, 0.05004675313830376, 0.017911044880747795, -0.022426962852478027, 0.02386648952960968, 0.048113469034433365, 0.019357038661837578, -0.002517858287319541, -0.029423190280795097, 0.028521211817860603, -0.05840958282351494, -0.012776044197380543, 0.017962582409381866, -0.01567179150879383, -0.015199352987110615, 0.012643004767596722, -0.029876958578824997, -0.0249872375279665, 0.03534381836652756, 0.101801797747612, 0.03406399488449097, 0.019412729889154434, -0.010000490583479404, 0.04440544545650482, -0.030102815479040146, 0.013825519010424614, -0.044385481625795364, -0.010058943182229996, 0.0010560265509411693, 0.041663751006126404, -0.03816172108054161, 0.08877356350421906, -0.023763906210660934, -0.006386797409504652, -0.024817945435643196, 0.044150255620479584, -0.027911320328712463, 0.000926105072721839, 0.001310871448367834, -0.0035773259587585926, 0.0764659196138382, 0.05100255087018013, -0.014722555875778198, 0.05559156835079193, -0.004594834521412849, -0.02079017274081707, -0.022530900314450264, -0.00795386265963316, 0.021342789754271507, 0.07335181534290314, -0.026075268164277077, 0.008914732374250889, 0.01753322407603264, -0.0069273184053599834, 0.035924531519412994, 0.00012399553088471293, -0.019938107579946518, -0.04935246706008911, 0.042707495391368866, 0.009120894595980644, -0.01320446003228426, 0.0037938556633889675, 0.012204179540276527, 0.0350504107773304, 0.012184500694274902, -0.0026003792881965637, -0.0024818473029881716, 0.04481826350092888, -0.013052721507847309, 0.012387349270284176, 0.02480985037982464, -0.004745144862681627, -0.06215699017047882, 0.03789535164833069, -0.017288392409682274, -0.022394193336367607, -0.0457959845662117, 0.03360568359494209, -0.04595459997653961, -0.022618845105171204, 0.005046497564762831, 0.051109205931425095, 0.010980802588164806, 0.027529854327440262, -0.04080300033092499, -0.07298189401626587, 0.009789488278329372, -0.03327316418290138, -0.00857933983206749, 0.0204020943492651, 0.021939890459179878, 0.027651019394397736, 0.021481657400727272, 0.016294503584504128, 0.011743368580937386, 0.009478502906858921, 0.07409017533063889, -0.07845642417669296, -0.04345502331852913, -0.04225948452949524, -5.561924621970595e-33, 0.0066660623997449875, -0.03711331635713577, -0.007129280362278223, -0.04297618567943573, -0.059097327291965485, -0.0502101331949234, -0.020257653668522835, -0.031112054362893105, -0.011271674185991287, 0.01850360818207264, -0.01137907337397337, -0.0019144919933751225, 0.0033998002763837576, -0.044844821095466614, 0.01851288601756096, -0.02927287109196186, 0.040778450667858124, 0.03433980420231819, -0.0009700489463284612, 0.011211945675313473, 0.03483075648546219, 0.0069914329797029495, 0.016167055815458298, 0.062032800167798996, -0.016634609550237656, 0.012989761307835579, -0.015359578654170036, -0.027136731892824173, 0.029430340975522995, 0.056611694395542145, 0.0032077475916594267, -0.008236684836447239, -0.027171609923243523, -0.009234197437763214, 0.0076991356909275055, 0.04769863188266754, 0.0035113522317260504, 0.0017954519717022777, -0.053188711404800415, 0.059227462857961655, 0.06062506511807442, -0.029148239642381668, 0.027858015149831772, -0.035159651190042496, -0.01465238444507122, 0.03375387191772461, -0.012290160171687603, 0.04030284285545349, -0.06684525310993195, -0.01367957890033722, -0.008920202031731606, -0.0075683495961129665, 0.0349125936627388, 0.017746925354003906, 0.05663586035370827, -0.0668044239282608, 0.07354182004928589, 0.013224179856479168, 0.07205191999673843, -0.028506051748991013, 0.0230708010494709, -0.07125111669301987, 0.00419364869594574, -0.029626723378896713, 0.020937180146574974, 0.020083408802747726, 0.03723929077386856, 0.012562445364892483, 0.09725531935691833, -0.046645935624837875, -0.024180622771382332, 0.031202934682369232, -0.011052712798118591, -0.10645060986280441, -0.004036718048155308, -0.03615832328796387, 0.011654091998934746, -0.03562445566058159, 0.025226302444934845, -0.030156824737787247, -0.06286036223173141, 0.0013744981260970235, -0.039460305124521255, 0.02734995447099209, 0.024023113772273064, -0.04358877241611481, 0.0017640413716435432, -0.029653921723365784, -0.029429933056235313, -0.020928803831338882, -0.030161011964082718, 0.05322860926389694, 0.015523385256528854, 0.020541666075587273, 0.05465509369969368, -0.022531677037477493, -0.03320595994591713, -0.022507289424538612, -0.009469833225011826, 0.01009373925626278, 0.017929164692759514, -0.00978775229305029, -0.026692934334278107, 0.016483834013342857, 0.010557403787970543, -0.00948468130081892, 0.023643748834729195, -0.028335923328995705, -0.05394688993692398, -2.016332291532308e-05, -0.03304377570748329, 0.03067922033369541, 0.036969881504774094, 0.004713600967079401, 0.028086354956030846, 0.02802916057407856, -0.028360988944768906, -0.02237609028816223, -0.012592879123985767, -0.057074710726737976, 0.05215686932206154, 0.04888486489653587, -0.010958736762404442, 0.026001904159784317, 0.011588728986680508, -0.024808097630739212, 0.01918954774737358, -0.022802278399467468, -0.0539938360452652, -0.03823012858629227, 0.009570694528520107, -0.01644175499677658, 2.123994136127294e-07, 0.03943442180752754, 0.03630891069769859, -0.03761390224099159, 0.04563114419579506, 0.009122098796069622, 0.05207809805870056, 0.05368005856871605, -0.007393673527985811, -0.02829597517848015, 0.09079687297344208, -0.01865784451365471, -0.0003923402982763946, 0.06224584951996803, 0.07643411308526993, 0.0047835432924330235, 0.0012899597641080618, -0.03484464809298515, -0.022961467504501343, -0.005929260049015284, -0.03075714409351349, -0.01129975076764822, 0.002764267846941948, 0.04432487115263939, -0.00896221399307251, 0.013865365646779537, 0.017291661351919174, 0.012016499415040016, -0.001423799665644765, 0.00045420738752000034, 0.039236556738615036, -0.013565902598202229, 0.011769159696996212, 0.036211322993040085, 0.0014819115167483687, 0.02180485427379608, -0.04334937781095505, 0.055010441690683365, -0.09686238318681717, 0.030777134001255035, -0.016430433839559555, -0.08140382170677185, 0.007095457520335913, -0.0016663036076352, 0.02134212851524353, -0.02804408222436905, -0.0016705538146197796, 0.005639664363116026, 0.10601214319467545, -0.009991982951760292, -0.025789890438318253, -0.002336228033527732, 0.003422412322834134, 0.0166541188955307, -0.014477157033979893, 0.024950390681624413, 0.02212037332355976, 0.017037106677889824, 0.029604468494653702, 0.025405846536159515, -0.010319933295249939, -0.018586119636893272, 0.05215420946478844, -0.006057252641767263, 0.10037624835968018, -0.0836728885769844, 0.04002966359257698, -0.019667653366923332, 1.50121602941797e-34, 0.054123278707265854, -0.029241010546684265, -0.023481421172618866, -0.0041754464618861675, 0.0003540499019436538, -0.013006513938307762, 0.06949342042207718, 0.00348111055791378, 0.0345931239426136, 0.011323200538754463, -0.005566319450736046]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To determine if two sentences are similar, you can compute the cosine similarity between their embeddings. The cosine similarity is a measure of the similarity between two non-zero vectors of an inner product space that measures the cosine of the angle between them"
      ],
      "metadata": {
        "id": "wSGteKf_TJB6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "simil = np.dot(embeddings[0], embeddings[1])\n",
        "print(f\"The similarity between '{sentences[0]}' and '{sentences[1]}' is: {round(simil*100,2)}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwHkGTFJTVqB",
        "outputId": "9bdd978d-5ee5-406e-9717-7674d60b02cc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The similarity between 'I like Hamburguers' and 'I like Pizza' is: 38.55%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "simil = np.dot(embeddings[1], embeddings[3])\n",
        "print(f\"The similarity between '{sentences[1]}' and '{sentences[3]}' is: {round(simil*100,2)}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OJ7OezCTsXt",
        "outputId": "04276b41-b56a-4032-8297-45b7467af010"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The similarity between 'I like Pizza' and 'The weather is cool outside' is: 6.31%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### SpacyEmbeddings"
      ],
      "metadata": {
        "id": "nCdmKHILWRnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import SpacyEmbeddings\n",
        "s_emb = SpacyEmbeddings()"
      ],
      "metadata": {
        "id": "g6qnYqQxWVfL"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [\"I like Hamburguers\", \"I like Pizza\", \"I like Programming\", \"The weather is cool outside\"]\n",
        "s_embeddings = [s_emb.embed_query(sen) for sen in sentences]"
      ],
      "metadata": {
        "id": "3xDhePyaXI3T"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(s_embeddings[0])\n",
        "len(s_embeddings[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9Cft4_eXMJs",
        "outputId": "e2713c0b-602f-4d30-afe7-5de9e498b5a9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.9977489113807678, 0.362231969833374, -0.662943959236145, 0.5147702097892761, 0.31709548830986023, -0.7147340774536133, 1.5253783464431763, 0.020086606964468956, 0.5353927612304688, -0.23669223487377167, 0.47885391116142273, 0.08887312561273575, 0.053243715316057205, -0.24007479846477509, -0.6280664801597595, -0.6196134686470032, 0.2873343825340271, 0.4676531255245209, -0.015774646773934364, -0.22300869226455688, -0.6867689490318298, -0.6164547801017761, -0.6381105780601501, 0.027278026565909386, 0.3923916816711426, -0.24323658645153046, 0.016015464439988136, 0.3272424638271332, -0.05785775184631348, -0.05975094437599182, 0.3496571481227875, 0.0060227313078939915, -0.00799520779401064, 0.6956599354743958, -0.674931526184082, -0.14988763630390167, 0.002886096714064479, 0.22291512787342072, 0.2595116198062897, -0.6202573776245117, -0.45861172676086426, 0.24878716468811035, -0.3522361218929291, 0.15946926176548004, -0.6310560703277588, -0.3818489611148834, 0.859626829624176, 1.074246883392334, -0.17595608532428741, -0.34863170981407166, -0.27806153893470764, -0.7932028770446777, 1.004256248474121, -0.7436847686767578, -0.16384245455265045, -0.08713998645544052, -0.1003655418753624, -0.5442721247673035, -0.04650290682911873, 0.11236067861318588, 0.5995305180549622, 0.17238084971904755, 0.5454965233802795, 0.07584305852651596, -0.36612167954444885, 0.36195775866508484, 0.2807472050189972, -1.1379947662353516, -0.7025823593139648, 0.6549718379974365, -0.6786131858825684, 0.32744935154914856, 1.2098665237426758, -0.6048998236656189, -0.5209197402000427, 0.5984964370727539, 0.13726511597633362, 0.6294105648994446, -0.2822915017604828, -0.22285354137420654, -0.018033653497695923, -0.40894433856010437, -0.06690436601638794, 0.3265693485736847, 0.08313367515802383, 1.4161592721939087, -1.1444129943847656, -0.05243595317006111, 0.28774070739746094, -0.15636788308620453, -0.1877002716064453, 0.09900727868080139, 2.018049478530884, -0.02007216215133667, -0.17904210090637207, 0.45928236842155457]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "96"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "simil = np.dot(s_embeddings[0], s_embeddings[1])\n",
        "print(f\"The similarity between '{sentences[0]}' and '{sentences[2]}' is: {round(simil,2)}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19qcHXEgXPXA",
        "outputId": "208e3d3e-2660-43e3-dd54-2e3bf06880fc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The similarity between 'I like Hamburguers' and 'I like Programming' is: 23.09%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "simil = np.dot(s_embeddings[1], s_embeddings[3])\n",
        "print(f\"The similarity between '{sentences[1]}' and '{sentences[3]}' is: {round(simil,2)}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdDbxMAHXq7n",
        "outputId": "0a962ebf-5cda-4a12-e519-191b3785a9a8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The similarity between 'I like Pizza' and 'The weather is cool outside' is: 4.31%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The quality of an embedding model depends on several factors such as the size of the dataset, the complexity of the data, and the type of problem you are trying to solve. Some models may perform better than others for a given domain"
      ],
      "metadata": {
        "id": "a19VyXZzYyfR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VectoreStores"
      ],
      "metadata": {
        "id": "reD8mJtmZn6i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Chroma** is a vector store and embeddings database designed to make it easy to build AI applications with embeddings. It is an open-source, lightweight embedding database that can be used to store embeddings locally."
      ],
      "metadata": {
        "id": "R8Rml5ZlZpzv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter"
      ],
      "metadata": {
        "id": "vR5rTJiuYzDa"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaders = [\n",
        "    PyPDFLoader(\"/content/Attention.pdf\"), # https://arxiv.org/abs/1706.03762\n",
        "    PyPDFLoader(\"/content/Bert.pdf\")      # https://arxiv.org/abs/1810.04805v2\n",
        "]\n",
        "\n",
        "docs = []\n",
        "for loader in loaders:\n",
        "  docs.extend(loader.load())"
      ],
      "metadata": {
        "id": "31CDua9KaHQN"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 1500,\n",
        "    chunk_overlap = 150\n",
        ")\n",
        "\n",
        "splits = text_splitter.split_documents(docs)"
      ],
      "metadata": {
        "id": "9QlbLBCecZXn"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(splits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jXYZd8Oc5N1",
        "outputId": "0e4def18-5041-4fde-93a1-c419209421f1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "90"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "splits[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plDYDdEec7jI",
        "outputId": "45b3ca67-41d8-4bb7-f36c-0e2e704aa062"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='our model establishes a new single-model state-of-the-art BLEU score of 41.8 after\\ntraining for 3.5 days on eight GPUs, a small fraction of the training costs of the\\nbest models from the literature. We show that the Transformer generalizes well to\\nother tasks by applying it successfully to English constituency parsing both with\\nlarge and limited training data.\\n∗Equal contribution. Listing order is random. Jakob proposed replacing RNNs with self-attention and started\\nthe effort to evaluate this idea. Ashish, with Illia, designed and implemented the first Transformer models and\\nhas been crucially involved in every aspect of this work. Noam proposed scaled dot-product attention, multi-head\\nattention and the parameter-free position representation and became the other person involved in nearly every\\ndetail. Niki designed, implemented, tuned and evaluated countless model variants in our original codebase and\\ntensor2tensor. Llion also experimented with novel model variants, was responsible for our initial codebase, and\\nefficient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of and\\nimplementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating\\nour research.\\n†Work performed while at Google Brain.\\n‡Work performed while at Google Research.\\n31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.arXiv:1706.03762v6  [cs.CL]  24 Jul 2023', metadata={'source': '/content/Attention.pdf', 'page': 0})"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "persist_dir = \"docs/chroma\""
      ],
      "metadata": {
        "id": "8E9fem4HZgA3"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm rf ./docs/chroma/ # remove old database files"
      ],
      "metadata": {
        "id": "2PKkUAc2Z0pg"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectordb = Chroma.from_documents(\n",
        "    documents=splits,\n",
        "    embedding = HuggingFaceEmbeddings(),\n",
        "    persist_directory=persist_dir\n",
        ")"
      ],
      "metadata": {
        "id": "Qi_8HECMZ-UI"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vectordb._collection.count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pA22eR6YdaVJ",
        "outputId": "ff34f05e-85ea-4eb3-dbc8-aaaadec9c552"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "354\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Similarity search"
      ],
      "metadata": {
        "id": "qbr16rFQdunl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What are attention mechanism\""
      ],
      "metadata": {
        "id": "98JwpiWvdj0C"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs_f = vectordb.similarity_search(question, k=3)"
      ],
      "metadata": {
        "id": "FZaryvTjeqp_"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs_f[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Y1KXKd1e1RF",
        "outputId": "5587f0e2-1acb-4815-ff98-187645d7d730"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='Attention Visualizations\\nInput-Input Layer5\\nIt\\nis\\nin\\nthis\\nspirit\\nthat\\na\\nmajority\\nof\\nAmerican\\ngovernments\\nhave\\npassed\\nnew\\nlaws\\nsince\\n2009\\nmaking\\nthe\\nregistration\\nor\\nvoting\\nprocess\\nmore\\ndifficult\\n.\\n<EOS>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\nIt\\nis\\nin\\nthis\\nspirit\\nthat\\na\\nmajority\\nof\\nAmerican\\ngovernments\\nhave\\npassed\\nnew\\nlaws\\nsince\\n2009\\nmaking\\nthe\\nregistration\\nor\\nvoting\\nprocess\\nmore\\ndifficult\\n.\\n<EOS>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\nFigure 3: An example of the attention mechanism following long-distance dependencies in the\\nencoder self-attention in layer 5 of 6. Many of the attention heads attend to a distant dependency of\\nthe verb ‘making’, completing the phrase ‘making...more difficult’. Attentions here shown only for\\nthe word ‘making’. Different colors represent different heads. Best viewed in color.\\n13', metadata={'page': 12, 'source': '/content/Attention.pdf'})"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for doc in docs_f:\n",
        "  print(doc.metadata)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wju64hw8fI1r",
        "outputId": "d05a2053-fb80-48c7-bb98-1ca84ec45494"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'page': 12, 'source': '/content/Attention.pdf'}\n",
            "{'page': 12, 'source': '/content/Attention.pdf'}\n",
            "{'page': 12, 'source': '/content/Attention.pdf'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question_2 = \"What is a transformer\"\n",
        "docs_f = vectordb.similarity_search(question_2, k=5)"
      ],
      "metadata": {
        "id": "ouiLdW_mkm0e"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs_f[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MefA9imEkwCF",
        "outputId": "bbc5476b-51f0-4ed5-bba8-80247e039199"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='Figure 1: The Transformer - model architecture.\\nThe Transformer follows this overall architecture using stacked self-attention and point-wise, fully\\nconnected layers for both the encoder and decoder, shown in the left and right halves of Figure 1,\\nrespectively.\\n3.1 Encoder and Decoder Stacks\\nEncoder: The encoder is composed of a stack of N= 6 identical layers. Each layer has two\\nsub-layers. The first is a multi-head self-attention mechanism, and the second is a simple, position-\\nwise fully connected feed-forward network. We employ a residual connection [ 11] around each of\\nthe two sub-layers, followed by layer normalization [ 1]. That is, the output of each sub-layer is\\nLayerNorm( x+ Sublayer( x)), where Sublayer( x)is the function implemented by the sub-layer\\nitself. To facilitate these residual connections, all sub-layers in the model, as well as the embedding\\nlayers, produce outputs of dimension dmodel = 512 .', metadata={'page': 2, 'source': '/content/Attention.pdf'})"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for doc in docs_f:\n",
        "  print(doc.metadata)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4XRerNYk2MB",
        "outputId": "54c5ee98-fcd3-4e77-a4b5-5667a35f7e1e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'page': 2, 'source': '/content/Attention.pdf'}\n",
            "{'page': 2, 'source': '/content/Attention.pdf'}\n",
            "{'page': 2, 'source': '/content/Attention.pdf'}\n",
            "{'page': 1, 'source': '/content/Attention.pdf'}\n",
            "{'page': 1, 'source': '/content/Attention.pdf'}\n"
          ]
        }
      ]
    }
  ]
}