{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMnFynU4Z5RqBuRIeMGZJRL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alex112525/LangChain-with-LLMs/blob/main/Loaders_and_Splitting_Langchain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain pypdf tiktoken"
      ],
      "metadata": {
        "id": "VJDrhudjg5u7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Document Loaders"
      ],
      "metadata": {
        "id": "xZvsvnokTX_h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Document loaders are used to load data from a source as Document’s. A Document is a piece of text and associated metadata. For example, there are document loaders for loading a simple .txt file, for loading the text contents of any web page, or even for loading a transcript of a YouTube video"
      ],
      "metadata": {
        "id": "Xg6GVodUhiYQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PDF's"
      ],
      "metadata": {
        "id": "b9Bau1EOjed-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We upload a paper called [\"Attention is all you need\"](https://arxiv.org/abs/1706.03762)"
      ],
      "metadata": {
        "id": "UN6YHKavhslH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "sQsRAoicgy4B"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "loader = PyPDFLoader(\"/content/Attention.pdf\")\n",
        "pages = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(pages) #No. of pages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNT1zssbh38J",
        "outputId": "76a3dba5-6c13-43c3-801e-92ba258620db"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "page = pages[0]\n",
        "print(page.page_content[586:1500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_N9Bu0NiVJ7",
        "outputId": "8a0e7c8d-1bfd-49fe-f46f-bd334a7df283"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Abstract\n",
            "The dominant sequence transduction models are based on complex recurrent or\n",
            "convolutional neural networks that include an encoder and a decoder. The best\n",
            "performing models also connect the encoder and decoder through an attention\n",
            "mechanism. We propose a new simple network architecture, the Transformer,\n",
            "based solely on attention mechanisms, dispensing with recurrence and convolutions\n",
            "entirely. Experiments on two machine translation tasks show these models to\n",
            "be superior in quality while being more parallelizable and requiring significantly\n",
            "less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-\n",
            "to-German translation task, improving over the existing best results, including\n",
            "ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task,\n",
            "our model establishes a new single-model state-of-the-art BLEU score of 41.8 after\n",
            "training for 3.5 days on eight GPUs, a smal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metadata is a dictionary of any metadata you want to store about the text (source url, author, etc.)."
      ],
      "metadata": {
        "id": "lBSjhHZtjVgD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "page.metadata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2atuKA5iqQw",
        "outputId": "20656332-8430-486b-a7f3-c8543c1fe3a1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'source': '/content/Attention.pdf', 'page': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## WEB pages\n"
      ],
      "metadata": {
        "id": "PKhUZsdfjkZo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import WebBaseLoader\n",
        "loader = WebBaseLoader(\"https://docs.langchain.com/docs/\")"
      ],
      "metadata": {
        "id": "bAY2HYQmC67l"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "web = loader.load()"
      ],
      "metadata": {
        "id": "wUzqU4UcDc6Q"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(web[0].page_content[355:800])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9azIZGMDimi",
        "outputId": "5fabc85e-ea5f-4a1b-d36b-2028a8319423"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LangChainLangChain is a framework for developing applications powered by language models.\n",
            "We believe that the most powerful and differentiated applications will not only call out to a language model via an api, but will also:Be data-aware: connect a language model to other sources of dataBe agentic: Allow a language model to interact with its environmentAs such, the LangChain framework is designed with the objective in mind to enable those t\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Document Spliting"
      ],
      "metadata": {
        "id": "TCjW0aTgTbJF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RecursiveCharacterTextSplitter"
      ],
      "metadata": {
        "id": "C_MRQ88eWlnK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter"
      ],
      "metadata": {
        "id": "tctpLgS2TfcG"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **RecursiveCharacterTextSplitter** is a splitter that splits documents recursively by different characters - for example: starting with “\\n\\n”, then “\\n”, then \" \".\n",
        "\n",
        "This is nice because it will try to keep all the semantically relevant content in the same place for as long as possible. The chunkSize controls the max size (in terms of number of characters) of the final documents. The chunkOverlap specifies how much overlap there should be between chunks. This is often helpful to make sure that the text isn’t split weirdly"
      ],
      "metadata": {
        "id": "zvKsKScjYJ4b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chunk_size = 20\n",
        "chunk_overlap = 5\n",
        "\n",
        "r_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=chunk_size,\n",
        "    chunk_overlap=chunk_overlap\n",
        ")\n",
        "c_splitter = CharacterTextSplitter(\n",
        "    chunk_size=chunk_size,\n",
        "    chunk_overlap=chunk_overlap,\n",
        "    separator = ' ',\n",
        ")"
      ],
      "metadata": {
        "id": "Lzuy0JSoTm3k"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"The CharacterTextSplitter and RecursiveCharacterTextSplitter are a splitters that splits text into characters. It is used to split text into characters for indexing purposes.\""
      ],
      "metadata": {
        "id": "Qp1RqICPT1SR"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r_splitter.split_text(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLpkqWMcUAES",
        "outputId": "d8af98c4-0c6b-40b5-c5f1-1741ccac894d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The',\n",
              " 'CharacterTextSplitt',\n",
              " 'plitter',\n",
              " 'and',\n",
              " 'RecursiveCharacterT',\n",
              " 'cterTextSplitter',\n",
              " 'are a splitters',\n",
              " 'that splits text',\n",
              " 'text into',\n",
              " 'into characters. It',\n",
              " 'It is used to split',\n",
              " 'text into',\n",
              " 'into characters for',\n",
              " 'for indexing',\n",
              " 'purposes.']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c_splitter.split_text(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVRsWMTtUCmw",
        "outputId": "869bf704-fa2c-412d-8bbe-5ddff16c09a1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.text_splitter:Created a chunk of size 21, which is longer than the specified 20\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 30, which is longer than the specified 20\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The',\n",
              " 'CharacterTextSplitter',\n",
              " 'and',\n",
              " 'RecursiveCharacterTextSplitter',\n",
              " 'are a splitters that',\n",
              " 'that splits text',\n",
              " 'text into',\n",
              " 'into characters. It',\n",
              " 'It is used to split',\n",
              " 'split text into',\n",
              " 'into characters for',\n",
              " 'for indexing',\n",
              " 'purposes.']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Doc = \"\"\"\n",
        "There are two main value props the LangChain framework provides:\n",
        "\n",
        "Components: LangChain provides modular abstractions for the components neccessary to work with language models. LangChain also has collections of implementations for all these abstractions. The components are designed to be easy to use, regardless of whether you are using the rest of the LangChain framework or not.\n",
        "Use-Case Specific Chains: Chains can be thought of as assembling these components in particular ways in order to best accomplish a particular use case. These are intended to be a higher level interface through which people can easily get started with a specific use case. These chains are also designed to be customizable.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "C0de7Fs_WRX1"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r_sep_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=100,\n",
        "    chunk_overlap=10,\n",
        "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
        ")"
      ],
      "metadata": {
        "id": "5F_3nO9DV4i_"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r_sep_splitter.split_text(Doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGNzbJNRWHlx",
        "outputId": "bf68d679-fe95-4706-90b8-2b91dab272e3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['There are two main value props the LangChain framework provides:',\n",
              " 'Components: LangChain provides modular abstractions for the components neccessary to work with',\n",
              " 'work with language models. LangChain also has collections of implementations for all these',\n",
              " 'all these abstractions. The components are designed to be easy to use, regardless of whether you',\n",
              " 'you are using the rest of the LangChain framework or not.',\n",
              " 'Use-Case Specific Chains: Chains can be thought of as assembling these components in particular',\n",
              " 'ways in order to best accomplish a particular use case. These are intended to be a higher level',\n",
              " 'level interface through which people can easily get started with a specific use case. These chains',\n",
              " 'chains are also designed to be customizable.']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TokenTextSplitter"
      ],
      "metadata": {
        "id": "wN7Q1nZ2Wujc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import TokenTextSplitter"
      ],
      "metadata": {
        "id": "0REq2wlMXFeo"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **TokenTextSplitter** is a function in Langchain that splits a raw text string by first converting the text into BPE tokens, then splitting these tokens into chunks and converting the tokens within a single chunk back into text. It is an implementation of a splitter that looks at tokens"
      ],
      "metadata": {
        "id": "rSQq9K0MaHOS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "token_splitter = TokenTextSplitter(chunk_size=20,\n",
        "                                  chunk_overlap=3)"
      ],
      "metadata": {
        "id": "TU_PRnodWyvB"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_splitter.split_text(Doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_IrHUIicXSrF",
        "outputId": "66e29cbf-fc9c-47c9-8cff-66e569e486f5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\nThere are two main value props the LangChain framework provides:\\n\\nComponents: LangChain',\n",
              " ': LangChain provides modular abstractions for the components neccessary to work with language models. Lang',\n",
              " ' models. LangChain also has collections of implementations for all these abstractions. The components are designed to',\n",
              " ' are designed to be easy to use, regardless of whether you are using the rest of the LangChain',\n",
              " ' the LangChain framework or not.\\nUse-Case Specific Chains: Chains can be thought of as',\n",
              " ' thought of as assembling these components in particular ways in order to best accomplish a particular use case. These',\n",
              " ' case. These are intended to be a higher level interface through which people can easily get started with a',\n",
              " ' started with a specific use case. These chains are also designed to be customizable.\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ]
}